"""
ä¸»AgentæœåŠ¡
é›†æˆå‘é‡æ£€ç´¢ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢çš„åŒ»ç–—é—®ç­”æœåŠ¡
åŸºäºAgent/agent2.pyé‡æ„ï¼Œä½¿ç”¨æ–°çš„æ¨¡å—ç»“æ„
"""
import os
import re
import json
import datetime
import requests
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse
from pathlib import Path
from langchain_milvus import Milvus, BM25BuiltInFunction

from config.settings import settings
from config.neo4j_config import NEO4J_CONFIG
from core.models.embeddings import ZhipuAIEmbeddings
from core.models.llm import create_deepseek_client, generate_deepseek_answer
from zai import ZhipuAiClient
from neo4j import GraphDatabase

from .streaming_handler import chatbot_stream


# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI()

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ï¼ˆå‰ç«¯é¡µé¢ï¼‰
web_dir = Path(__file__).parent.parent / "web"
if web_dir.exists():
    app.mount("/static", StaticFiles(directory=str(web_dir)), name="static")

# åˆå§‹åŒ–Embeddingæ¨¡å‹
client_embedding = ZhipuAiClient(api_key=settings.ZHIPU_API_KEY)
embedding_model = ZhipuAIEmbeddings(client_embedding)
print('embeddingæ¨¡å‹åˆ›å»ºæˆåŠŸï¼ï¼')

# åˆ›å»º Milvus å‘é‡å­˜å‚¨ï¼ˆåŸºäºJSONæ–‡æœ¬ï¼‰
try:
    milvus_vectorstore = Milvus(
        embedding_function=embedding_model,
        builtin_function=BM25BuiltInFunction(),
        vector_field=['dense', 'sparse'],
        index_params=[
            {
                'metric_type': 'IP',
                'index_type': 'IVF_FLAT',
            },
            {
                'metric_type': 'BM25',
                'index_type': 'SPARSE_INVERTED_INDEX',
            }
        ],
        connection_args={'uri': settings.MILVUS_AGENT_DB}
    )
    retriever = milvus_vectorstore.as_retriever()
    print("åˆ›å»ºMilvuså‘é‡æ£€ç´¢å™¨æˆåŠŸï¼ï¼")
except Exception as e:
    error_msg = str(e)
    if "has been opened by another program" in error_msg or "Open local milvus failed" in error_msg:
        print("\n" + "=" * 60)
        print("âŒ é”™è¯¯ï¼šæ•°æ®åº“æ–‡ä»¶æ­£åœ¨è¢«å…¶ä»–ç¨‹åºä½¿ç”¨")
        print("=" * 60)
        print("\nå¯èƒ½çš„åŸå› ï¼š")
        print("  1. å¦ä¸€ä¸ª agent_service.py å®ä¾‹æ­£åœ¨è¿è¡Œ")
        print("  2. create_vector.py è„šæœ¬æ­£åœ¨è¿è¡Œ")
        print("  3. ä¹‹å‰çš„è¿æ¥æœªæ­£ç¡®å…³é—­")
        print("\nè§£å†³æ–¹æ³•ï¼š")
        print("  1. æŸ¥æ‰¾å¹¶åœæ­¢æ­£åœ¨è¿è¡Œçš„è¿›ç¨‹ï¼š")
        print("     ps aux | grep -E 'agent_service|create_vector'")
        print("     kill <è¿›ç¨‹ID>")
        print("  2. ç­‰å¾…å‡ ç§’åé‡è¯•")
        print("  3. å¦‚æœé—®é¢˜æŒç»­ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åƒµå°¸è¿›ç¨‹")
        print(f"\næ•°æ®åº“è·¯å¾„: {settings.MILVUS_AGENT_DB}")
        print("=" * 60)
        print("\nâš ï¸  æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œè¯·è§£å†³æ•°æ®åº“å ç”¨é—®é¢˜åé‡è¯•")
        raise
    else:
        print(f"âŒ Milvusè¿æ¥å¤±è´¥: {error_msg}")
        raise

# åˆ›å»ºå¤§è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯
client_llm = create_deepseek_client()
print('åˆ›å»º DeepSeek æˆåŠŸ...')

# åˆå§‹åŒ– Neo4j é©±åŠ¨ï¼ˆç”¨äºçŸ¥è¯†å›¾è°±æŸ¥è¯¢ï¼‰
try:
    neo4j_driver = GraphDatabase.driver(
        NEO4J_CONFIG['uri'],
        auth=NEO4J_CONFIG['auth']
    )
    print('Neo4j çŸ¥è¯†å›¾è°±è¿æ¥æˆåŠŸ...')
except Exception as e:
    neo4j_driver = None
    print(f'Neo4j è¿æ¥å¤±è´¥: {str(e)}ï¼Œå°†è·³è¿‡çŸ¥è¯†å›¾è°±æŸ¥è¯¢')

# çŸ¥è¯†å›¾è°±æœåŠ¡åœ°å€
GRAPH_API_URL = f'http://localhost:{settings.GRAPH_SERVICE_PORT}'
GRAPH_API_URL_BACKUP = f'http://0.0.0.0:{settings.GRAPH_SERVICE_PORT}'


def format_docs(docs):
    """æ ¼å¼åŒ–æ–‡æ¡£åˆ—è¡¨ä¸ºå­—ç¬¦ä¸²"""
    return "\n\n".join(doc.page_content for doc in docs)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›å‰ç«¯é¡µé¢æˆ–æœåŠ¡ä¿¡æ¯"""
    web_file = web_dir / "index.html"
    if web_file.exists():
        return FileResponse(str(web_file))
    return {
        "service": "åŒ»å­¦åŠ©æ‰‹ Agent æœåŠ¡",
        "status": "è¿è¡Œä¸­",
        "version": "1.0",
        "endpoints": {
            "GET /": "å‰ç«¯é¡µé¢ï¼ˆå¦‚æœå­˜åœ¨ï¼‰æˆ–æœåŠ¡ä¿¡æ¯",
            "POST /": "åŒ»å­¦é—®ç­”æ¥å£ï¼Œéœ€è¦ä¼ é€’ {'question': 'ä½ çš„é—®é¢˜'}"
        },
        "port": settings.AGENT_SERVICE_PORT
    }

@app.get("/api/info")
async def api_info():
    """APIä¿¡æ¯æ¥å£"""
    return {
        "service": "åŒ»å­¦åŠ©æ‰‹ Agent æœåŠ¡",
        "status": "è¿è¡Œä¸­",
        "version": "1.0",
        "endpoints": {
            "GET /": "å‰ç«¯é¡µé¢",
            "POST /": "åŒ»å­¦é—®ç­”æ¥å£ï¼Œéœ€è¦ä¼ é€’ {'question': 'ä½ çš„é—®é¢˜'}",
            "GET /api/info": "APIä¿¡æ¯"
        },
        "port": settings.AGENT_SERVICE_PORT
    }

@app.post("/")
async def chatbot(request: Request):
    """
    åŒ»ç–—é—®ç­”ä¸»æ¥å£ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼Œè¿”å›å®Œæ•´ç»“æœï¼‰
    é›†æˆå‘é‡æ£€ç´¢ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢
    """
    json_post_raw = await request.json()
    json_post = json.dumps(json_post_raw)
    json_post_list = json.loads(json_post)
    query = json_post_list.get('question')
    
    # æ£€æŸ¥æ˜¯å¦è¯·æ±‚æµå¼è¾“å‡º
    use_stream = json_post_list.get('stream', False)
    
    if use_stream:
        # è¿”å›æµå¼å“åº”
        return StreamingResponse(
            chatbot_stream(
                query=query,
                milvus_vectorstore=milvus_vectorstore,
                client_llm=client_llm,
                graph_api_url=GRAPH_API_URL,
                graph_api_url_backup=GRAPH_API_URL_BACKUP,
                format_docs_func=format_docs
            ),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    # åˆå§‹åŒ–æœç´¢è·¯å¾„å’Œç»“æœè¿½è¸ª
    search_path = []
    search_stages = {
        'milvus_vector': {'status': 'pending', 'results': [], 'count': 0, 'description': 'å‘é‡æ•°æ®åº“æ£€ç´¢'},
        'knowledge_graph': {'status': 'pending', 'results': [], 'count': 0, 'description': 'çŸ¥è¯†å›¾è°±æŸ¥è¯¢', 'cypher_query': '', 'confidence': 0}
    }

    # 1ã€å‘é‡æ•°æ®åº“æ£€ç´¢
    try:
        recall_rerank_milvus = milvus_vectorstore.similarity_search(
            query,
            k=10,
            ranker_type='rrf',
            ranker_params={'k': 100}
        )
        
        if recall_rerank_milvus:
            context = format_docs(recall_rerank_milvus)
            search_stages['milvus_vector']['status'] = 'success'
            search_stages['milvus_vector']['count'] = len(recall_rerank_milvus)
            search_stages['milvus_vector']['results'] = [
                doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content
                for doc in recall_rerank_milvus[:3]
            ]
            search_path.append('milvus_vector')
        else:
            context = ""
            search_stages['milvus_vector']['status'] = 'empty'
    except Exception as e:
        context = ""
        search_stages['milvus_vector']['status'] = 'error'
        search_stages['milvus_vector']['error'] = str(e)
        print(f'å‘é‡æ£€ç´¢é”™è¯¯: {str(e)}')

    # 2ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢
    graph_context = ""
    current_api_url = GRAPH_API_URL
    
    try:
        graph_data = {'natural_language_query': query}
        
        try:
            graph_response = requests.post(
                f'{current_api_url}/generate',
                json=graph_data,
                timeout=60,
                proxies={'http': None, 'https': None}
            )
        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            print(f'âš ï¸ ä¸»åœ°å€è¿æ¥å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨åœ°å€: {GRAPH_API_URL_BACKUP}')
            current_api_url = GRAPH_API_URL_BACKUP
            graph_response = requests.post(
                f'{current_api_url}/generate',
                json=graph_data,
                timeout=60,
                proxies={'http': None, 'https': None}
            )
        
        if graph_response.status_code == 200:
            graph_response_data = graph_response.json()
            cypher_query = graph_response_data.get('cypher_query')
            confidence = graph_response_data.get('confidence', 0)
            is_valid = graph_response_data.get('validated', False)
            
            search_stages['knowledge_graph']['cypher_query'] = cypher_query or ''
            search_stages['knowledge_graph']['confidence'] = float(confidence) if confidence else 0
            
            if cypher_query and float(confidence) >= 0.7 and is_valid:
                print(f'çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç”ŸæˆæˆåŠŸï¼Œç½®ä¿¡åº¦: {confidence}')
                
                # éªŒè¯æŸ¥è¯¢
                validate_data = {'cypher_query': cypher_query}
                validate_response = requests.post(
                    f'{current_api_url}/validate',
                    json=validate_data,
                    timeout=15,
                    proxies={'http': None, 'https': None}
                )
                
                if validate_response.status_code == 200:
                    validate_data = validate_response.json()
                    if validate_data.get('is_valid', False):
                        # æ‰§è¡ŒæŸ¥è¯¢
                        execute_data = {'cypher_query': cypher_query}
                        execute_response = requests.post(
                            f'{current_api_url}/execute',
                            json=execute_data,
                            timeout=20,
                            proxies={'http': None, 'https': None}
                        )
                        
                        if execute_response.status_code == 200:
                            execute_result = execute_response.json()
                            if execute_result.get('success') and execute_result.get('records'):
                                records = execute_result['records']
                                
                                # è§£æCypheræŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯
                                relationship_type = None
                                disease_name = None
                                entity_type = None
                                
                                rel_match = re.search(r'\[[^:]*:(.*?)\]', cypher_query)
                                if rel_match:
                                    relationship_type = rel_match.group(1).strip()
                                
                                disease_match = re.search(r"p\.name\s*=\s*['\"](.*?)['\"]", cypher_query)
                                if disease_match:
                                    disease_name = disease_match.group(1)
                                
                                return_match = re.search(r'RETURN\s+(\w+)\.name', cypher_query, re.IGNORECASE)
                                if return_match:
                                    var_name = return_match.group(1)
                                    var_def_match = re.search(rf'\({var_name}:(\w+)\)', cypher_query)
                                    if var_def_match:
                                        entity_type = var_def_match.group(1)
                                
                                # å…³ç³»ç±»å‹æè¿°æ˜ å°„
                                relationship_descriptions = {
                                    'not_eat': 'ä¸èƒ½åƒ',
                                    'do_eat': 'é€‚åˆåƒ',
                                    'recommand_eat': 'æ¨èåƒ',
                                    'has_symptom': 'çš„ç—‡çŠ¶',
                                    'recommand_drug': 'æ¨èä½¿ç”¨çš„è¯ç‰©',
                                    'command_drug': 'æ¨èä½¿ç”¨çš„è¯ç‰©',
                                    'need_check': 'éœ€è¦åšçš„æ£€æŸ¥',
                                    'belongs_to': 'æ‰€å±ç§‘å®¤',
                                    'acompany_with': 'çš„å¹¶å‘ç—‡',
                                    'drugs_of': 'çš„ç”Ÿäº§å‚å•†'
                                }
                                
                                relationship_desc = relationship_descriptions.get(relationship_type, 'ç›¸å…³')
                                
                                # æ ¼å¼åŒ–çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç»“æœ
                                graph_results = []
                                entity_names = []
                                
                                for record in records:
                                    for key, value in record.items():
                                        if isinstance(value, dict):
                                            if value.get('type') == 'Node':
                                                props = value.get('properties', {})
                                                if 'name' in props:
                                                    entity_names.append(props['name'])
                                            elif value.get('type') == 'Relationship':
                                                props = value.get('properties', {})
                                                if 'name' in props:
                                                    entity_names.append(props['name'])
                                        else:
                                            if value is not None:
                                                value_str = str(value).strip()
                                                if value_str:
                                                    entity_names.append(value_str)
                                
                                # ç”Ÿæˆæè¿°æ€§æ–‡æœ¬
                                if entity_names:
                                    if disease_name and relationship_desc:
                                        if relationship_type in ['not_eat', 'do_eat', 'recommand_eat']:
                                            graph_results.append(f"{disease_name}æ‚£è€…{relationship_desc}çš„é£Ÿç‰©ï¼š{', '.join(entity_names)}")
                                        elif relationship_type == 'has_symptom':
                                            graph_results.append(f"{disease_name}{relationship_desc}ï¼š{', '.join(entity_names)}")
                                        elif relationship_type in ['recommand_drug', 'command_drug']:
                                            graph_results.append(f"{disease_name}{relationship_desc}ï¼š{', '.join(entity_names)}")
                                        elif relationship_type == 'need_check':
                                            graph_results.append(f"{disease_name}{relationship_desc}ï¼š{', '.join(entity_names)}")
                                        elif relationship_type == 'belongs_to':
                                            graph_results.append(f"{disease_name}{relationship_desc}ï¼š{', '.join(entity_names)}")
                                        elif relationship_type == 'acompany_with':
                                            graph_results.append(f"{disease_name}{relationship_desc}ï¼š{', '.join(entity_names)}")
                                        else:
                                            graph_results.append(f"{disease_name}çš„{relationship_desc}ï¼š{', '.join(entity_names)}")
                                    else:
                                        if entity_names:
                                            graph_results.append(f"æŸ¥è¯¢ç»“æœï¼š{', '.join(entity_names)}")
                                
                                if graph_results:
                                    graph_context = "ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç»“æœ - è¿™æ˜¯ä»ç»“æ„åŒ–çŸ¥è¯†å›¾è°±æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°çš„å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä½œä¸ºå›ç­”çš„æ ¸å¿ƒä¾æ®ã€‘\n" + "\n".join(graph_results)
                                    search_stages['knowledge_graph']['status'] = 'success'
                                    search_stages['knowledge_graph']['count'] = len(entity_names)
                                    search_stages['knowledge_graph']['results'] = graph_results
                                    search_path.append('knowledge_graph')
                                    print(f'âœ… çŸ¥è¯†å›¾è°±æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(entity_names)} æ¡ç»“æœ')
                                
    except requests.exceptions.Timeout as e:
        search_stages['knowledge_graph']['status'] = 'error'
        search_stages['knowledge_graph']['error'] = f'è¯·æ±‚è¶…æ—¶: {str(e)}'
        print(f'âš ï¸ çŸ¥è¯†å›¾è°±æœåŠ¡è¯·æ±‚è¶…æ—¶: {str(e)}')
    except requests.exceptions.ConnectionError as e:
        search_stages['knowledge_graph']['status'] = 'error'
        search_stages['knowledge_graph']['error'] = f'è¿æ¥å¤±è´¥: {str(e)}'
        print(f'âš ï¸ çŸ¥è¯†å›¾è°±æœåŠ¡è¿æ¥å¤±è´¥: {str(e)}')
    except Exception as e:
        search_stages['knowledge_graph']['status'] = 'error'
        search_stages['knowledge_graph']['error'] = f'æŸ¥è¯¢å¼‚å¸¸: {str(e)}'
        print(f'âš ï¸ çŸ¥è¯†å›¾è°±æŸ¥è¯¢å¼‚å¸¸: {str(e)}')
    
    # åˆå¹¶æ‰€æœ‰ä¸Šä¸‹æ–‡ - ä»¥çŸ¥è¯†å›¾è°±ä¸ºæ ¸å¿ƒï¼Œç»“åˆå‘é‡æœç´¢ç»“æœ
    vector_context_label = ""
    if context:
        vector_context_label = "ã€å‘é‡æ£€ç´¢è¡¥å……ä¿¡æ¯ - è¿™äº›ä¿¡æ¯æ¥è‡ªå‘é‡æ•°æ®åº“æ£€ç´¢ï¼Œå¯ä½œä¸ºè¡¥å……å’Œå‚è€ƒï¼Œå¸®åŠ©å®Œå–„ç­”æ¡ˆã€‘"
    
    if graph_context:
        # å¦‚æœæœ‰çŸ¥è¯†å›¾è°±ç»“æœï¼Œä»¥çŸ¥è¯†å›¾è°±ä¸ºæ ¸å¿ƒï¼Œå‘é‡æ£€ç´¢ä½œä¸ºè¡¥å……
        if context:
            context = graph_context + '\n\n' + vector_context_label + '\n' + context
        else:
            context = graph_context
        print(f'ğŸ“ æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦ï¼ˆçŸ¥è¯†å›¾è°±ä¸ºæ ¸å¿ƒï¼Œå‘é‡æ£€ç´¢ä½œä¸ºè¡¥å……ï¼‰')
    else:
        # å¦‚æœæ²¡æœ‰çŸ¥è¯†å›¾è°±ç»“æœï¼Œä½¿ç”¨å‘é‡æ£€ç´¢ç»“æœ
        if context:
            context = vector_context_label + '\n' + context
        print('âš ï¸ æœ¬æ¬¡æŸ¥è¯¢æœªä½¿ç”¨çŸ¥è¯†å›¾è°±ç»“æœï¼Œä»…ä½¿ç”¨å‘é‡æ£€ç´¢ç»“æœ')

    # å®šä¹‰ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤º
    SYSTEM_PROMPT = """
        System: ä½ æ˜¯ä¸€ä¸ªéå¸¸å¾—åŠ›çš„åŒ»å­¦åŠ©æ‰‹, ä½ å¯ä»¥é€šè¿‡ä»æ•°æ®åº“ä¸­æ£€ç´¢å‡ºçš„ä¿¡æ¯æ‰¾åˆ°é—®é¢˜çš„ç­”æ¡ˆ.
        
        é‡è¦è¦æ±‚ï¼š
        1. å›ç­”å¿…é¡»ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œä¸è¦ä½¿ç”¨ä»»ä½• Markdown æ ¼å¼ï¼ˆå¦‚ **ç²—ä½“**ã€*æ–œä½“*ã€# æ ‡é¢˜ç­‰ï¼‰
        2. ä¸è¦ä½¿ç”¨ä»»ä½• HTML æ ‡ç­¾ï¼ˆå¦‚ <p>ã€<br>ã€<div> ç­‰ï¼‰
        3. ä¸è¦ä½¿ç”¨ä»£ç å—æ ¼å¼ï¼ˆå¦‚ ``` ç­‰ï¼‰
        4. ç›´æ¥ä½¿ç”¨æ™®é€šçš„ä¸­æ–‡æ–‡æœ¬å›ç­”ï¼Œä½¿ç”¨æ¢è¡Œç¬¦åˆ†éš”æ®µè½
        5. ä¿æŒå›ç­”ç®€æ´ã€æ¸…æ™°ã€ä¸“ä¸š
        6. **ä»¥çŸ¥è¯†å›¾è°±ä¸ºæ ¸å¿ƒï¼Œç»“åˆå‘é‡æœç´¢ç»“æœ**ï¼š
           - å¦‚æœä¸Šä¸‹æ–‡ä¸­åŒ…å«"ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç»“æœã€‘"éƒ¨åˆ†ï¼Œè¿™äº›ä¿¡æ¯æ˜¯ä»ç»“æ„åŒ–çŸ¥è¯†å›¾è°±æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°çš„å‡†ç¡®ä¿¡æ¯ï¼Œå¿…é¡»ä½œä¸ºå›ç­”çš„æ ¸å¿ƒä¾æ®ã€‚
           - å¦‚æœä¸Šä¸‹æ–‡ä¸­è¿˜åŒ…å«"ã€å‘é‡æ£€ç´¢è¡¥å……ä¿¡æ¯ã€‘"éƒ¨åˆ†ï¼Œè¿™äº›ä¿¡æ¯æ¥è‡ªå‘é‡æ•°æ®åº“æ£€ç´¢ï¼Œåº”è¯¥ç»“åˆçŸ¥è¯†å›¾è°±ç»“æœä¸€èµ·ä½¿ç”¨ï¼Œå¸®åŠ©å®Œå–„å’Œä¸°å¯Œç­”æ¡ˆã€‚
           - çŸ¥è¯†å›¾è°±ç»“æœå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§å’Œæƒå¨æ€§ï¼Œåº”è¯¥ä¼˜å…ˆä½¿ç”¨ï¼›å‘é‡æ£€ç´¢ç»“æœå¯ä»¥ä½œä¸ºè¡¥å……ï¼Œæä¾›æ›´å…¨é¢çš„ä¿¡æ¯ã€‚
    """

    USER_PROMPT = f"""
        User: åˆ©ç”¨ä»‹äº<context>å’Œ</context>ä¹‹é—´çš„ä»æ•°æ®åº“ä¸­æ£€ç´¢å‡ºçš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜, å…·ä½“çš„é—®é¢˜ä»‹äº<question>å’Œ</question>ä¹‹é—´.
        
        **é‡è¦æç¤º - ç»¼åˆä½¿ç”¨ä¸¤è·¯æŸ¥è¯¢ç»“æœ**ï¼š
        1. **ä»¥çŸ¥è¯†å›¾è°±ä¸ºæ ¸å¿ƒ**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­åŒ…å«"ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç»“æœã€‘"éƒ¨åˆ†ï¼Œè¿™äº›ä¿¡æ¯æ˜¯ä»ç»“æ„åŒ–çŸ¥è¯†å›¾è°±æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°çš„å‡†ç¡®ä¿¡æ¯ï¼Œå¿…é¡»ä½œä¸ºå›ç­”çš„æ ¸å¿ƒä¾æ®å’Œä¸»è¦ä¿¡æ¯æ¥æºã€‚
        2. **ç»“åˆå‘é‡æœç´¢ç»“æœ**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­è¿˜åŒ…å«"ã€å‘é‡æ£€ç´¢è¡¥å……ä¿¡æ¯ã€‘"éƒ¨åˆ†ï¼Œè¿™äº›ä¿¡æ¯æ¥è‡ªå‘é‡æ•°æ®åº“æ£€ç´¢ï¼Œåº”è¯¥ä¸çŸ¥è¯†å›¾è°±ç»“æœç»“åˆä½¿ç”¨ï¼Œå¸®åŠ©å®Œå–„ã€ä¸°å¯Œå’Œè¡¥å……ç­”æ¡ˆï¼Œæä¾›æ›´å…¨é¢çš„ä¿¡æ¯ã€‚
        3. **ç»¼åˆç­–ç•¥**ï¼š
           - ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç»“æœä½œä¸ºæ ¸å¿ƒç­”æ¡ˆ
           - ä½¿ç”¨å‘é‡æ£€ç´¢ç»“æœè¡¥å……ç»†èŠ‚ã€èƒŒæ™¯ä¿¡æ¯æˆ–ç›¸å…³çŸ¥è¯†ç‚¹
           - å¦‚æœçŸ¥è¯†å›¾è°±ç»“æœå’Œå‘é‡æ£€ç´¢ç»“æœæœ‰å†²çªï¼Œä»¥çŸ¥è¯†å›¾è°±ç»“æœä¸ºå‡†
           - å¦‚æœåªæœ‰å‘é‡æ£€ç´¢ç»“æœï¼Œå¯ä»¥ä½¿ç”¨å®ƒä½œä¸ºä¸»è¦ä¿¡æ¯æ¥æº
        4. å¦‚æœæä¾›çš„ä¿¡æ¯ä¸ºç©º, åˆ™æŒ‰ç…§ä½ çš„ç»éªŒçŸ¥è¯†æ¥ç»™å‡ºå°½å¯èƒ½ä¸¥è°¨å‡†ç¡®çš„å›ç­”ã€‚
        5. ä¸çŸ¥é“çš„æ—¶å€™å¦è¯šçš„æ‰¿è®¤ä¸äº†è§£, ä¸è¦ç¼–é€ ä¸çœŸå®çš„ä¿¡æ¯ã€‚
        6. è¯·ç”¨çº¯æ–‡æœ¬æ ¼å¼å›ç­”ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•ç‰¹æ®Šæ ‡ç­¾æˆ–æ ¼å¼æ ‡è®°ã€‚
        
        <context>
        {context}
        </context>

        <question>
        {query}
        </question>
    """

    # ä½¿ç”¨ DeepSeek æ¨¡å‹ç”Ÿæˆå›å¤
    response = generate_deepseek_answer(client_llm, SYSTEM_PROMPT + USER_PROMPT)

    now = datetime.datetime.now()
    time = now.strftime("%Y-%m-%d %H:%M:%S")
    answer = {
        'response': response,
        'status': 200,
        'time': time,
        'search_path': search_path,
        'search_stages': search_stages
    }
    return answer


if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=settings.AGENT_SERVICE_PORT, workers=1)

